{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このノートブックについて\n",
    "\n",
    "### 概要\n",
    "これまでの Tutorial では OpenAI Gym にプリインストールされている環境での訓練であったが、<br>\n",
    "今回はオリジナルの環境を用いて強化学習を行う。<br>\n",
    "CartPole を継承して作成された CartPoleCustom を環境として用いる。<br>\n",
    "CartPoleCustom は元の CartPole に対して以下の点で異なる。\n",
    "\n",
    "1. 台車と地面の間に摩擦がある\n",
    "1. 台車と棒の間に摩擦がある\n",
    "\n",
    "### 身につけられる知識\n",
    "1. オリジナルの環境を用いた強化学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CartPole Custom について\n",
    "<img src=\"./images/about_cartpolecustom_1.png\" alt=\"about_cartpolecustom_1.png\" />\n",
    "<img src=\"./images/about_cartpolecustom_2.png\" alt=\"about_cartpolecustom_1.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils import dir_util\n",
    "import os.path\n",
    "\n",
    "# Azure Machine Learning core imports\n",
    "import azureml.core\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core.compute import ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.contrib.train.rl import ReinforcementLearningEstimator, Ray\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "import consts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace と Compute target の設定\n",
    "1つめのチュートリアルで説明済みなので、詳細は省略します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace の取得\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=consts.tenant_id)\n",
    "\n",
    "ws = Workspace(subscription_id=consts.subscription_id,\n",
    "               resource_group=consts.resource_group,\n",
    "               workspace_name=consts.workspace_name,\n",
    "               auth=interactive_auth)\n",
    "print(ws.name, ws.location, ws.resource_group, sep = ' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cluster を compute target として指定する\n",
    "\n",
    "**compute target** は訓練スクリプト、シミュレーションスクリプトを実行する際に用いられるコンピュータリソースです。<br>\n",
    "compute target にはローカルコンピュータを指定することもできますし、クラウド上のコンピュータを指定することもできます。<br>\n",
    "詳しくは [What are compute targets in Azure Machine Learning?](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target) を御覧ください。\n",
    "\n",
    "このデモでは computing cluster を compute target として用います。<br>\n",
    "`cc-dllab-d2v2`という名称の computing cluster を探し、なければこれを作成して使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "import os\n",
    "\n",
    "# Cluster の名前とサイズを選択する\n",
    "compute_name = consts.cc_cpu_name\n",
    "compute_min_nodes = 0\n",
    "compute_max_nodes = 4\n",
    "vm_size = \"STANDARD_D2_V2\"\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    print(\"次の Cluster が見つかりました: \" + compute_name)\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "else:\n",
    "    print(\"新しい Cluster を作成します\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=vm_size,\n",
    "        min_nodes=compute_min_nodes, \n",
    "        max_nodes=compute_max_nodes)\n",
    "        \n",
    "    # Cluster の作成\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練\n",
    "\n",
    "CartPoleCustom の訓練スクリプトは `files/cartpolecustom_training.py` となります。\n",
    "\n",
    "`files/cartpolecustom_training.py` の中で独自の環境である `CartPoleCustom` が使われています。<br>\n",
    "独自のクラスは `create_env` 関数を実装する必用があり、この関数への引数として下記の `env_config` が渡されることになります。\n",
    "\n",
    "`files/cartpolecustom_training.py` への引数によって、カートと地面の摩擦、カートと棒の摩擦、棒の長さを設定することができます。<br>\n",
    "この引数の指定が `script_params` 内の `env_config` で行われています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_algorithm = \"SAC\"\n",
    "rl_environment = \"CartPoleCustom-v0\"\n",
    "\n",
    "script_params = {\n",
    "\n",
    "    # 訓練アルゴリズム\n",
    "    \"--run\": training_algorithm,  # \"SAC\"\n",
    "    \n",
    "    # 環境名\n",
    "    \"--env\": rl_environment,  # \"CartPoleCustom-v0\"\n",
    "    \n",
    "    # 訓練に関係する config を設定する\n",
    "    \"--config\": '\\'{\"num_workers\": 1, \"target_entropy\": 0.1, \"prioritized_replay\": \"\", \"env_config\": {\"friction_cart\": 0.5, \"friction_pole\": 0.5, \"pole_length\": 1.25}}\\'',  # 独自クラスのコンストラクタ引数\n",
    "    \n",
    "    # 訓練の終了条件\n",
    "    # Simulationをスタート (リセット) してから終了するまでをエピソードという\n",
    "    # ここでは複数回エピソードの平均報酬が 200 に達するか、訓練時間が 300秒を超えると訓練を終了する\n",
    "    \"--stop\": '\\'{\"episode_reward_mean\": 198}\\'', \n",
    "    \n",
    "    # チェックポイント (モデルの重みなど) の作成頻度\n",
    "    # ここでは 2エピソード毎に作成する\n",
    "    \"--checkpoint-freq\": 2,\n",
    "    \n",
    "    # 訓練終了時にもチェックポイントを作成する。値は空欄でOK。\n",
    "    \"--checkpoint-at-end\": \"\",\n",
    "    \n",
    "    # Tensorboard で開くことのできるログの場所を指定する\n",
    "    \"--local-dir\": './logs',\n",
    "}\n",
    "\n",
    "#  Reinforcement learning estimator\n",
    "training_estimator = ReinforcementLearningEstimator(\n",
    "    \n",
    "    # 訓練スクリプトが入っているフォルダを指定\n",
    "    source_directory='files',\n",
    "    \n",
    "    # 訓練スクリプトのファイル名\n",
    "    entry_script=\"cartpolecustom_training.py\",\n",
    "    \n",
    "    # 上で定義した訓練スクリプトへ渡す引数\n",
    "    script_params=script_params,\n",
    "     \n",
    "    # compute target を指定する。ここではこのノートブックを開いている compute instance を指定する\n",
    "    compute_target=compute_target,\n",
    "            \n",
    "    # 今現在は Ray() で固定\n",
    "    rl_framework=Ray(),\n",
    "\n",
    "    # pip を使ってライブラリを追加する。最新の ray を使用する。\n",
    "    pip_packages=[\"ray[rllib]==0.8.7\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験の作成\n",
    "experiment_name = 'Demo03-CartPoleCustom-SAC-Train'  # 任意の名称を入力\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "# 訓練を実行する\n",
    "training_run = exp.submit(training_estimator)\n",
    "\n",
    "# 訓練をモニタリングする\n",
    "RunDetails(training_run).show()\n",
    "\n",
    "# 訓練完了を待つ\n",
    "training_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 子の実行へのハンドルを取得する\n",
    "次の手順で子の実行へのハンドルを取得できます。<br>\n",
    "本デモでは1つしか子の実行がないので、その `child_run_0` をそのハンドルとします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "child_run_0 = None\n",
    "timeout = 30\n",
    "while timeout > 0 and not child_run_0:\n",
    "    child_runs = list(training_run.get_children())\n",
    "    print('子の実行数:', len(child_runs))\n",
    "    if len(child_runs) > 0:\n",
    "        child_run_0 = child_runs[0]\n",
    "        break\n",
    "    time.sleep(2) # Wait for 2 seconds\n",
    "    timeout -= 2\n",
    "\n",
    "print('子の実行の情報:')\n",
    "print(child_run_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練済みモデルで推論を行い、結果を確認する\n",
    "RLlib が提供する補助スクリプトである `rollout.py` で訓練済みモデルを評価することができます。<br>\n",
    "詳しくは [Evaluating Trained Policies](https://ray.readthedocs.io/en/latest/rllib-training.html#evaluating-trained-policies) を御覧ください。<br>\n",
    "ここではこのスクリプトを用いて先程の訓練モデルを Machine learning work space に登録し、これを使用します。<br>\n",
    "先程の訓練で `checkpoint-freq` と `checkpoint-at-end` を指定していればチェックポイントが生成されています。\n",
    "\n",
    "ここではこれらのチェックポイントへのアクセス方法とそれを使って訓練済みモデルを評価する方法を示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練の生成物を取得する\n",
    "訓練済みモデルを含む、訓練中の生成物は既定のデータストアに保存されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "run_id = child_run_0.id # 上で取得した子の実行の ID。親の実行ではないので注意\n",
    "run_artifacts_path = os.path.join('azureml', run_id)\n",
    "print(\"生成物のパス:\", run_artifacts_path)\n",
    "\n",
    "# デフォルトデータストアのファイルからデータセットオブジェクトを作成する\n",
    "datastore = ws.get_default_datastore()\n",
    "training_artifacts_ds = Dataset.File.from_files(datastore.path(os.path.join(run_artifacts_path, '**')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認のため、データセットに含まれるファイル数をプリントします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_paths = training_artifacts_ds.to_path()\n",
    "print(\"データセットに含まれるファイルの数:\", len(artifacts_paths))\n",
    "\n",
    "# 以下をコメントアウトすると全てのファイルパスを print します\n",
    "#print(\"生成物のパス: \", artifacts_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チェックポイントを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# チェックポイントの一覧を取得し、最後のものを使用する\n",
    "checkpoint_files = [\n",
    "    os.path.basename(file) for file in training_artifacts_ds.to_path() \\\n",
    "        if os.path.basename(file).startswith('checkpoint-') and \\\n",
    "            not os.path.basename(file).endswith('tune_metadata')\n",
    "]\n",
    "\n",
    "checkpoint_numbers = []\n",
    "for file in checkpoint_files:\n",
    "    checkpoint_numbers.append(int(file.split('-')[1]))\n",
    "\n",
    "print(\"チェックポイント番号の一覧:\", checkpoint_numbers)\n",
    "\n",
    "last_checkpoint_number = max(checkpoint_numbers)\n",
    "print(\"最後のチェックポイント番号:\", last_checkpoint_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練済みモデルを登録する\n",
    "Machine learning work space に最後に保存された訓練済みモデルを登録します。<br>\n",
    "訓練目標達成時に保存されたモデルなので、最も性能が高いものであると仮定しています。<br>\n",
    "登録されたモデルは再利用することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "import tempfile\n",
    "\n",
    "last_checkpoint_file = [file for file in training_artifacts_ds.to_path() \\\n",
    "        if os.path.basename(file).endswith(f\"checkpoint-{last_checkpoint_number}\")][0]\n",
    "print(\"最後に記録されたチェックポイントファイル:\", last_checkpoint_file)\n",
    "\n",
    "last_checkpoint = os.path.dirname(os.path.join(run_artifacts_path, os.path.normpath(last_checkpoint_file[1:])))\n",
    "print(\"最後に記録されたチェックポイント:\", last_checkpoint)\n",
    "\n",
    "model_name = consts.model_name_cartpolecustom_sac\n",
    "model_path_prefix = os.path.join(tempfile.gettempdir(), 'tmp_training_artifacts')\n",
    "datastore.download(target_path=model_path_prefix, prefix=last_checkpoint.replace('\\\\', '/'), show_progress=True)\n",
    "\n",
    "# モデルの登録\n",
    "model = Model.register(\n",
    "    workspace=ws,\n",
    "    model_path=os.path.join(model_path_prefix, last_checkpoint),\n",
    "    model_name=model_name,\n",
    "    description='CartpoleCustom 用に訓練された SAC モデル')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 動画再生用環境の作成\n",
    "Ray の動画録画機能を使うために xvfb 環境を構築します。\n",
    "ここで作成した xvfb_env で推論が実行されます。\n",
    "\n",
    "(1) Dockerファイルを使い、xvfb, ffmpeg, python-opengl, その他の依存をインストールします。<br>\n",
    "注意: Renering off のときでも python-opengl は必用です。<br>\n",
    "Docker ファイルは ./files/docker フォルダに入っています。<br>\n",
    "\n",
    "(2) Headless display drivere をセットアップするため、xvfb-runコマンド経由で Python プロセスを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "video_capture = True\n",
    "\n",
    "with open(\"files/docker/Dockerfile\", \"r\") as f:\n",
    "    dockerfile=f.read()\n",
    "\n",
    "xvfb_env = Environment(name='xvfb-vdisplay')\n",
    "xvfb_env.docker.enabled = True\n",
    "xvfb_env.docker.base_image = None\n",
    "xvfb_env.docker.base_dockerfile = dockerfile\n",
    "    \n",
    "xvfb_env.python.user_managed_dependencies = True\n",
    "if video_capture:\n",
    "    xvfb_env.python.interpreter_path = \"xvfb-run -s '-screen 0 640x480x16 -ac +extension GLX +render' python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論の実行・動画の記録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {    \n",
    "    # 推論を実行する保存済のモデルの名前\n",
    "    '--model_name': consts.model_name_cartpolecustom_sac,\n",
    "\n",
    "    # 訓練アルゴリズム\n",
    "    \"--run\": training_algorithm,  # \"SAC\"\n",
    "    \n",
    "    # 環境名\n",
    "    \"--env\": rl_environment, # \"CartPoleCustom-v0\"\n",
    "    \n",
    "    # アルゴリズムパラメータ。訓練時と同じ摩擦と棒の長さを与えます。\n",
    "    \"--config\": '\\'{\"env_config\": {\"friction_cart\": 0.5, \"friction_pole\": 0.5, \"pole_length\": 1.25}}\\'',  # 独自クラスのコンストラクタ引数\n",
    "    \n",
    "    # 推論を行うエピソード数。今回は5回なので、5個動画が作成される。\n",
    "    \"--episodes\": 5,\n",
    "        \n",
    "    # 動画の保存先\n",
    "    \"--video-dir\": \"./logs/video\"\n",
    "}\n",
    "\n",
    "rollout_estimator = ReinforcementLearningEstimator(\n",
    "    # 推論スクリプトが入っているフォルダを指定\n",
    "    source_directory='files',\n",
    "    \n",
    "    # 推論スクリプトのファイル名\n",
    "    entry_script='cartpolecustom_rollout.py',\n",
    "    \n",
    "    # 上で定義した訓練スクリプトへ渡す引数\n",
    "    # どのようにパースされるかは cartpole_training.py を参照\n",
    "    script_params = script_params,\n",
    "        \n",
    "    # compute target を指定する。ここではこのノートブックを開いている compute instance を指定する\n",
    "    compute_target=compute_target,\n",
    "    \n",
    "    # R今現在は Ray() で固定\n",
    "    rl_framework=Ray(),\n",
    "    \n",
    "    # 動画記録用環境を指定する\n",
    "    environment=xvfb_env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験の作成\n",
    "experiment_name = 'Demo03-CartPoleCustom-SAC-Predict'  # 任意の名称を入力\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "# 訓練を実行する\n",
    "rollout_run = exp.submit(rollout_estimator)\n",
    "\n",
    "# 訓練をモニタリングする\n",
    "RunDetails(rollout_run).show()\n",
    "\n",
    "# 推論完了を待つ\n",
    "rollout_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 動画再生用の補助関数\n",
    "ノートブック内で動画を再生するための補助関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils import dir_util\n",
    "import shutil\n",
    "\n",
    "# データセットからこのローカルに動画をダウンロードするための補助関数\n",
    "def download_movies(artifacts_ds, movies, destination):\n",
    "    # 動画の保存先を作成    \n",
    "    if os.path.exists(destination):\n",
    "        dir_util.remove_tree(destination)\n",
    "    dir_util.mkpath(destination)\n",
    "\n",
    "    for i, artifact in enumerate(artifacts_ds.to_path()):\n",
    "        if artifact in movies:\n",
    "            print('ダウンロード中 {} ...'.format(artifact))\n",
    "            artifacts_ds.skip(i).take(1).download(target_path=destination, overwrite=True)\n",
    "\n",
    "    print('動画のダウンロードが完了しました。')\n",
    "\n",
    "\n",
    "# データセットのディレクトリ内の動画を探す補助関数\n",
    "def find_movies(movie_path):\n",
    "    print(\"動画を探すパス:\", movie_path)\n",
    "    mp4_movies = []\n",
    "    for root, _, files in os.walk(movie_path):\n",
    "        for name in files:\n",
    "            if name.endswith('.mp4'):\n",
    "                mp4_movies.append(os.path.join(root, name))\n",
    "    print('{} 個の動画が見つかりました。'.format(len(mp4_movies)))\n",
    "\n",
    "    return mp4_movies\n",
    "\n",
    "\n",
    "# このノートブックに動画を描画する補助関数\n",
    "from IPython.core.display import display, HTML\n",
    "def display_movie(movie_file):\n",
    "    display(\n",
    "        HTML('\\\n",
    "            <video alt=\"cannot display video\" autoplay loop> \\\n",
    "                <source src=\"{}\" type=\"video/mp4\"> \\\n",
    "            </video>'.format(movie_file)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 動画の再生\n",
    "\n",
    "動画を再生するためにまずローカルに動画をダウンロードします。<br>\n",
    "ロールアウトの成果物のデータセットを作成し、先に定義した補助関数を使ってダウンロードを行い、動画を再生します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論を実行した実行を取得する\n",
    "child_runs = list(rollout_run.get_children())\n",
    "print('子の実行数:', len(child_runs))\n",
    "child_run_0 = child_runs[0]\n",
    "\n",
    "run_id = child_run_0.id\n",
    "run_artifacts_path = os.path.join('azureml', run_id)\n",
    "print(\"実行の生成物へのパス:\", run_artifacts_path)\n",
    "\n",
    "# データセットオブジェクトの作成\n",
    "datastore = ws.get_default_datastore()\n",
    "rollout_artifacts_ds = Dataset.File.from_files(datastore.path(os.path.join(run_artifacts_path, '**')))\n",
    "\n",
    "artifacts_paths = rollout_artifacts_ds.to_path()\n",
    "print(\"データセット内のファイル数:\", len(artifacts_paths))\n",
    "\n",
    "# 一番最後に作成された動画を探す\n",
    "mp4_files = [file for file in rollout_artifacts_ds.to_path() if file.endswith('.mp4')]\n",
    "mp4_files.sort()\n",
    "\n",
    "last_movie = mp4_files[-1] if len(mp4_files) > 1 else None\n",
    "print(\"最後に保存された動画ファイル:\", last_movie)\n",
    "\n",
    "# 最後の動画をローカルにダウンロードする\n",
    "rollout_movies_path = os.path.join(\"rollout\", \"videos\")\n",
    "download_movies(rollout_artifacts_ds, [last_movie], rollout_movies_path)\n",
    "\n",
    "# ダウンロードされた動画を探す\n",
    "mp4_files = find_movies(rollout_movies_path)\n",
    "mp4_files.sort()\n",
    "\n",
    "last_movie = mp4_files[-1] if len(mp4_files) > 0 else None\n",
    "print(\"最後に保存された動画ファイル:\", last_movie)\n",
    "\n",
    "display_movie(last_movie) # 動画を描画する"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "vineetg"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "reinforcement-learning"
  ],
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "notice": "Copyright (c) Microsoft Corporation. All rights reserved.â€¯Licensed under the MIT License.â€¯ "
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
