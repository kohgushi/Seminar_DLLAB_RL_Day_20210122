{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このノートブックについて\n",
    "\n",
    "### 概要\n",
    "1. 2020 年現在において高い性能を持つアルゴリズム (SAC) を用いて Pendulum の強化学習を行う\n",
    "1. 2017 年に発表されたアルゴリズムである PPO でも同様に Pendulum の強化学習を行う\n",
    "1. SAC と PPO の結果を比較する\n",
    "\n",
    "### 身につけられる知識\n",
    "1. アルゴリズムを切り替える方法\n",
    "1. 実験の管理\n",
    "1. 性能指標の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils import dir_util\n",
    "import os.path\n",
    "\n",
    "# Azure Machine Learning core imports\n",
    "import azureml.core\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core.compute import ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.contrib.train.rl import ReinforcementLearningEstimator, Ray\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "import consts\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendulum について\n",
    "\n",
    "Pendulum は振り子に適切な力を加え、振り子を立たせることが目的となる問題です。\n",
    "\n",
    "<table style=\"width:25%\">\n",
    "  <tr>\n",
    "    <th>\n",
    "      <img src=\"./images/pendulum.png\" alt=\"Pendulum image\" /> \n",
    "    </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <th><p>Pendulum</p></th>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<img src=\"./images/about_pendulum_1.png\" alt=\"about pendulum\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace と Compute target の設定\n",
    "1つめのチュートリアルで説明済みなので、詳細は省略します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace の取得\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=consts.tenant_id)\n",
    "\n",
    "ws = Workspace(subscription_id=consts.subscription_id,\n",
    "               resource_group=consts.resource_group,\n",
    "               workspace_name=consts.workspace_name,\n",
    "               auth=interactive_auth)\n",
    "print(ws.name, ws.location, ws.resource_group, sep = ' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute target として Computing cluster を指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "import os\n",
    "\n",
    "# Cluster の名前とサイズを選択する\n",
    "compute_name = consts.cc_cpu_name\n",
    "compute_min_nodes = 0\n",
    "compute_max_nodes = 4\n",
    "vm_size = \"STANDARD_D2_V2\"\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    print(\"次の Cluster が見つかりました: \" + compute_name)\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "else:\n",
    "    print(\"新しい Cluster を作成します\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=vm_size,\n",
    "        min_nodes=compute_min_nodes, \n",
    "        max_nodes=compute_max_nodes)\n",
    "        \n",
    "    # Cluster の作成\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練\n",
    "アルゴリズムとして SAC を使い Pendulum を解く Agent の訓練を行います。<br>\n",
    "比較のため、PPO を使った訓練も行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAC による訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注意点\n",
    "2020 年 12 月現在、連続値問題に対して SAC を適用しようとすると必用なライブラリが不足しているため、エラーが発生します。<br>\n",
    "このエラーを回避するためには、以下を行う必用があります。\n",
    "* ray のバージョンを 0.8.7 以上にする\n",
    "* TensorFlow のバージョンを上げる\n",
    "* TensorFlow Probability をインストールする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_algorithm = \"SAC\"\n",
    "rl_environment = \"Pendulum-v0\"  # 新しい課題を使用する\n",
    "\n",
    "script_params = {\n",
    "\n",
    "    # 訓練アルゴリズム。ここでは SAC\n",
    "    \"--run\": training_algorithm,  # \"SAC\"\n",
    "    \n",
    "    # 環境。ここでは Pendulum-v0\n",
    "    \"--env\": rl_environment,  # \"Pendulum-v0\"\n",
    "    \n",
    "    # 訓練に関係する config を設定する\n",
    "    \"--config\": '\\'{\"num_gpus\": 0, \"num_workers\": 1}\\'',  # gpu は使わず、simulation は並列実行せず1つのプロセスで行う\n",
    "    \n",
    "    # 訓練の終了条件\n",
    "    # Simulationをスタート (リセット) してから終了するまでをエピソードという\n",
    "    # ここでは複数回エピソードの平均報酬が -500 に達するか、訓練時間が 900秒を超えると訓練を終了する\n",
    "    \"--stop\": '\\'{\"episode_reward_mean\": -500, \"time_total_s\": 900}\\'', \n",
    "    \n",
    "    # チェックポイント (モデルの重みなど) の作成頻度\n",
    "    # ここでは 2エピソード毎に作成する\n",
    "    \"--checkpoint-freq\": 50,\n",
    "    \n",
    "    # 訓練終了時にもチェックポイントを作成する。値は空欄でOK。\n",
    "    \"--checkpoint-at-end\": \"\",\n",
    "    \n",
    "    # Tensorboard で開くことのできるログの場所を指定する\n",
    "    \"--local-dir\": './logs'\n",
    "}\n",
    "\n",
    "training_estimator = ReinforcementLearningEstimator(\n",
    "\n",
    "    # 訓練スクリプトが入っているフォルダを指定\n",
    "    source_directory='files',\n",
    "    \n",
    "    # 訓練スクリプトのファイル名\n",
    "    entry_script='cartpole_training.py',\n",
    "    \n",
    "    # 上で定義した訓練スクリプトへ渡す引数\n",
    "    # どのようにパースされるかは cartpole_training.py を参照\n",
    "    script_params=script_params,\n",
    "    \n",
    "    # compute target を指定する。ここではこのノートブックを開いている compute instance を指定する\n",
    "    compute_target=compute_target,\n",
    "    \n",
    "    # 今現在は Ray() で固定\n",
    "    rl_framework=Ray(),\n",
    "    \n",
    "    # pip を使ってライブラリを追加する。最新の ray を使用する。\n",
    "    pip_packages=[\"ray[rllib]==0.8.7\", \"tensorflow==2.1.0\", \"tensorflow_probability==0.9.0\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験の作成\n",
    "experiment_name = 'Demo02-Pendulum-SAC-Train'  # 任意の名称を入力\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "# 訓練を実行する\n",
    "training_run = exp.submit(training_estimator)\n",
    "\n",
    "# 訓練をモニタリングする\n",
    "RunDetails(training_run).show()\n",
    "\n",
    "# 訓練完了を待つ\n",
    "training_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO による訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    \n",
    "    # 訓練アルゴリズム。ここでは SAC\n",
    "    \"--run\": \"PPO\",  # 比較のため、PPO を使用\n",
    "    \n",
    "    # 環境。ここでは Pendulum-v0\n",
    "    \"--env\": rl_environment,  # \"Pendulum-v0\"\n",
    "    \n",
    "    # 訓練に関係する config を設定する\n",
    "    \"--config\": '\\'{\"num_gpus\": 0, \"num_workers\": 1}\\'',  # gpu は使わず、simulation は並列実行せず1つのプロセスで行う\n",
    "    \n",
    "    # 訓練の終了条件\n",
    "    # Simulationをスタート (リセット) してから終了するまでをエピソードという\n",
    "    # ここでは複数回エピソードの平均報酬が -500 に達するか、訓練時間が 900秒を超えると訓練を終了する\n",
    "    \"--stop\": '\\'{\"episode_reward_mean\": -500, \"time_total_s\": 900}\\'', \n",
    "    \n",
    "    # チェックポイント (モデルの重みなど) の作成頻度\n",
    "    # ここでは 2エピソード毎に作成する\n",
    "    \"--checkpoint-freq\": 50,\n",
    "    \n",
    "    # 訓練終了時にもチェックポイントを作成する。値は空欄でOK。\n",
    "    \"--checkpoint-at-end\": \"\",\n",
    "    \n",
    "    # Tensorboard で開くことのできるログの場所を指定する\n",
    "    \"--local-dir\": './logs'\n",
    "}\n",
    "\n",
    "training_estimator_ppo = ReinforcementLearningEstimator(\n",
    "\n",
    "    # 訓練スクリプトが入っているフォルダを指定\n",
    "    source_directory='files',\n",
    "    \n",
    "    # 訓練スクリプトのファイル名\n",
    "    entry_script='cartpole_training.py',\n",
    "    \n",
    "    # 上で定義した訓練スクリプトへ渡す引数\n",
    "    # どのようにパースされるかは cartpole_training.py を参照\n",
    "    script_params=script_params,\n",
    "    \n",
    "    # compute target を指定する。ここではこのノートブックを開いている compute instance を指定する\n",
    "    compute_target=compute_target,\n",
    "    \n",
    "    # 今現在は Ray() で固定\n",
    "    rl_framework=Ray(),\n",
    "    \n",
    "    # pip を使ってライブラリを追加する。最新の ray を使用する。\n",
    "    pip_packages=[\"ray[rllib]==0.8.7\", \"tensorflow==2.1.0\", \"tensorflow_probability==0.9.0\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験の作成\n",
    "experiment_name_ppo = 'Demo02-Pendulum-PPO-Train'  # 任意の名称を入力\n",
    "exp_ppo = Experiment(workspace=ws, name=experiment_name_ppo)\n",
    "\n",
    "# 訓練を実行する\n",
    "training_run_ppo = exp_ppo.submit(training_estimator_ppo)\n",
    "\n",
    "# 訓練をモニタリングする\n",
    "RunDetails(training_run_ppo).show()\n",
    "\n",
    "# 訓練完了を待つ\n",
    "training_run_ppo.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の比較\n",
    "上記の実験は平均報酬が -500 に達するか、訓練時間が300秒を超えると終了します。<br>\n",
    "SAC は目標とする平均報酬を達成出来た一方、PPO は訓練時間が 900 秒以上になり、終了したと思います。<br>\n",
    "以下は、それぞれの平均報酬の推移の例です。\n",
    "\n",
    "<img src=\"./images/pendulum_sac_vs_ppo.png\" alt=\"SAC vs. PPO\" /> "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "adrosa"
   },
   {
    "name": "hoazari"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "reinforcement-learning"
  ],
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License.",
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
